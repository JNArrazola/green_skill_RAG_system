{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3b574dfb",
   "metadata": {},
   "source": [
    "# Green Job Detection and Normalization\n",
    "This notebooks aims to **detect** (know if a job contains green skills or not) and normalize (map the green skills from the *.csv* to the `ESCO` taxonomy)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6eaf3ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import faiss\n",
    "import json \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e4187c9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index contains 70318 vectors of dimension 3072.\n"
     ]
    }
   ],
   "source": [
    "index = faiss.read_index(\"../data/embeddings/job_skills_embeddings.index\")\n",
    "a, b = (index.ntotal, index.d,)\n",
    "\n",
    "print(f\"Index contains {a} vectors of dimension {b}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4c9a977b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['train staff to reduce food waste', 'teach students food waste reduction practices']\n",
      "['train staff to reduce food waste', 'inform staff on food waste reduction practices']\n",
      "['train staff to reduce food waste', 'educate workers on food recycling methods']\n",
      "['train staff to reduce food waste', 'educate staff on food waste reduction']\n",
      "['develop energy saving concepts', 'create concepts for energy saving']\n"
     ]
    }
   ],
   "source": [
    "id_to_text = json.load(open(\"../data/mapping/id_to_skill.json\", \"r\"))\n",
    "ctr = 0\n",
    "\n",
    "while ctr < 5:\n",
    "    print(id_to_text[str(ctr)])\n",
    "    ctr+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3d23bc6",
   "metadata": {},
   "source": [
    "Load indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7ecf7147",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Green skills index contains 3673 vectors of dimension 3072.\n",
      "Job skills index contains 70318 vectors of dimension 3072.\n"
     ]
    }
   ],
   "source": [
    "index_green_skills = faiss.read_index(\"../data/embeddings/esco_green_skills_text-embedding-3-large.index\")\n",
    "index_job_skills = faiss.read_index(\"../data/embeddings/job_skills_embeddings.index\")\n",
    "\n",
    "a, b = (index_green_skills.ntotal, index_green_skills.d,)\n",
    "c, d = (index_job_skills.ntotal, index_job_skills.d,)\n",
    "\n",
    "print(f\"Green skills index contains {a} vectors of dimension {b}.\")\n",
    "print(f\"Job skills index contains {c} vectors of dimension {d}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae0166f8",
   "metadata": {},
   "source": [
    "## Normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2be4a63e",
   "metadata": {},
   "source": [
    "Steps for normalization process: \n",
    "1. For every i-th job, get the top `k` nearest neighbors (`k` tweakable, using **cosine similarity** as distance metric) comparing them with the `ESCO` green skill taxonomy, in order to determine if it has green skills or not.\n",
    "2. Go through the `k` values, if the score is greater or equal than `THRESHOLD`, then we add it to the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "3f41441a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify this value in case of needing a different threshold for the \n",
    "# confidence of the green job detection\n",
    "THRESHOLD = 0.5\n",
    "\n",
    "# Modify this value in case of needing a different number of neighbors\n",
    "K_N = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86529ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load indexes\n",
    "index_green_skills = faiss.read_index(\"../data/embeddings/esco_green_skills_text-embedding-3-large.index\")\n",
    "index_job_skills = faiss.read_index(\"../data/embeddings/job_skills_embeddings.index\")\n",
    "\n",
    "# Load mappings\n",
    "id_to_job = json.load(open(\"../data/mapping/id_to_job.json\", \"r\"))\n",
    "id_to_skill = json.load(open(\"../data/mapping/id_to_skill.json\", \"r\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "3f169d8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6811/1510050521.py:15: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_results = pd.concat([df_results, pd.DataFrame({\"job_id\": str(id_to_job[str(i)]),\n"
     ]
    }
   ],
   "source": [
    "# Dataframe to store the results\n",
    "df_results = pd.DataFrame(columns=[\"job_id\", \"skill_id\", \"similarity_score\"])\n",
    "\n",
    "\"\"\"\n",
    "The same job can have multiple skills that are green, so we use a set to avoid duplicates\n",
    "of the form (job_id, skill_id), this way we ensure that each job-skill pair is unique in the results.\n",
    "\"\"\"\n",
    "job_skill_set = set()\n",
    "\n",
    "for i in range(0, index_job_skills.ntotal):\n",
    "    D, I = index_green_skills.search(np.array([index_job_skills.reconstruct(i)]), K_N)\n",
    "    \n",
    "    for score, idx in zip(D[0], I[0]):\n",
    "        if score >= THRESHOLD and (id_to_job[str(i)][0], id_to_skill[str(idx)][0]) not in job_skill_set:\n",
    "            df_results = pd.concat([df_results, pd.DataFrame({\"job_id\": str(id_to_job[str(i)]), \n",
    "                                                              \"skill_id\": list(id_to_skill.keys())[idx], \n",
    "                                                              \"similarity_score\": [score]})], ignore_index=True)\n",
    "            job_skill_set.add((id_to_job[str(i)][0], id_to_skill[str(idx)][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd0a10bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', None) \n",
    "\n",
    "df_results_copy = df_results.copy()\n",
    "\n",
    "# Eliminate brackets and quotes from the job_id and skill_id columns\n",
    "# ['identifier'] -> identifier\n",
    "\n",
    "df_results_copy[\"job_id\"] = df_results_copy[\"job_id\"].apply(lambda x: x[2: len(x)-2])\n",
    "df_results_copy.to_csv(\"../data/green_jobs_normalized.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
